{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 08 декабря 2020, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 08 декабря, -4 балла после 08:30 15 декабря, -6 баллов после 08:30 22 декабря, -8 баллов после 08:30 29 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0220, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем дерево решений (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
    "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс DecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=5, criterion='gini'):\n",
    "        \"\"\"\n",
    "        criterion -- критерий расщепления. необходимо релизовать три:\n",
    "        Ошибка классификации, Индекс Джини, Энтропийный критерий\n",
    "        max_depth -- максимальная глубина дерева\n",
    "        min_samples_split -- минимальное число объектов в листе, чтобы сделать новый сплит\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.num_class = -1\n",
    "        \n",
    "        # Для последнего задания\n",
    "        self.feature_importances_ = None\n",
    "        self.criterion = criterion\n",
    "        # Структура, которая описывает дерево\n",
    "        # Представляет словарь, где для  node_id (айдишник узла дерева) храним\n",
    "        # (тип_узла, айдишник признака сплита, порог сплита) если тип NON_LEAF_TYPE\n",
    "        # (тип_узла, предсказание класса, вероятность класса) если тип LEAF_TYPE\n",
    "        # Подразумевается, что у каждого node_id в дереве слева \n",
    "        # узел с айди 2 * node_id + 1, а справа 2 * node_id + 2\n",
    "        self.tree = dict()\n",
    "        if criterion == 'gini':\n",
    "            self.inform_crit = self.gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.inform_crit = self.entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.inform_crit = self.misclass\n",
    "            \n",
    "    def misclass(self, p):\n",
    "        return 1 - p.max(axis=1);\n",
    "    \n",
    "    def entropy(self, p):\n",
    "        return - np.sum(p * np.log2(p + 0.00001), axis=1)\n",
    "    \n",
    "    def gini(self, p):\n",
    "        return 1 - np.sum(p ** 2, axis=1)\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Разделяет объекты на 2 множества\n",
    "        x -- матрица объектов\n",
    "        y -- вектор ответов\n",
    "        feature_id -- айдишник признака, по которому делаем сплит\n",
    "        threshold -- порог, по которому делаем сплит\n",
    "        \"\"\"\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        \"\"\"\n",
    "        Находим оптимальный признак и порог для сплита\n",
    "        Здесь используемые разные impurity в зависимости от self.criterion\n",
    "        \"\"\"\n",
    "        # x - значения по признаку\n",
    "        # сортируем Х и y\n",
    "        sorted_indices = x.argsort()\n",
    "        X_sort, y_sort = x[sorted_indices], y[sorted_indices]\n",
    "        borders = int(self.min_samples_split / 2 - 1)\n",
    "        #отсекаем объекты, по которым точно не пройдет граница разбиения\n",
    "        if (borders != 0):\n",
    "            y_borders = y_sort[borders: -borders]\n",
    "        else:\n",
    "            y_borders = y_sort\n",
    "        #к индексам, в которых меняется метка класса, добавляем смещение, которое посчитали\n",
    "        indices = np.where(y_borders[:-1] != y_borders[1:])[0] + (borders + 1)\n",
    "        if len(indices) == 0:\n",
    "            return np.inf, None # нет сменяемости класса вообще\n",
    "        \n",
    "        eq_count = indices - np.append([borders], indices[:-1])\n",
    "        one_hot_code = np.zeros((indices.shape[0], self.num_class)) # строки - границы, столбцы - классы\n",
    "        one_hot_code[np.arange(indices.shape[0]), y_sort[indices - 1]] = 1\n",
    "\n",
    "        class_increments = one_hot_code * eq_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(y_sort[:borders], minlength=self.num_class)\n",
    "\n",
    "        # количество классов слева и справа в разбиении \n",
    "        l_class_cnt = np.cumsum(class_increments, axis=0)\n",
    "        r_class_cnt = np.bincount(y_sort, minlength=self.num_class) - l_class_cnt\n",
    "\n",
    "        # количество объектов слева и справа в разбиении\n",
    "        l_sizes = indices.reshape(l_class_cnt.shape[0], 1)\n",
    "        r_sizes = y_sort.shape[0] - l_sizes\n",
    "\n",
    "        unsertainty_l = self.inform_crit(l_class_cnt / l_sizes) * (l_sizes / (l_sizes+r_sizes)).T\n",
    "        unsertainty_r = self.inform_crit(r_class_cnt / r_sizes) * (r_sizes / (l_sizes+r_sizes)).T\n",
    "        unsertainty = unsertainty_l.T + unsertainty_r.T\n",
    "\n",
    "        idx = np.argmin(unsertainty)\n",
    "        \n",
    "        start_idx = l_sizes[idx][0] # индекс с которого начинается граница\n",
    "        \n",
    "        # мера неопределенности и порог\n",
    "        return unsertainty[idx], (X_sort[start_idx - 1] + X_sort[start_idx]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \"\"\"\n",
    "        Делаем новый узел в дереве\n",
    "        Решаем, терминальный он или нет\n",
    "        Если нет, то строим левый узел  с айди 2 * node_id + 1\n",
    "        И правый узел с  айди 2 * node_id + 2\n",
    "        \"\"\"\n",
    "        if ((len(y) < self.min_samples_split) or (depth >= self.max_depth)):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(), np.bincount(y).astype(float) / len(y))\n",
    "            return\n",
    "        \n",
    "        thresholds = np.array([self.__find_threshold(x[:, i], y) for i in range(x.shape[1])])\n",
    "\n",
    "        feature_id = thresholds[:, 0].argmin()\n",
    "        threshold = thresholds[feature_id, 1]\n",
    "        \n",
    "        if threshold == None:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(), np.bincount(y).astype(float) / len(y))\n",
    "        else:\n",
    "            X_l, X_r, y_l, y_r = self.__div_samples(x, y, feature_id, threshold)\n",
    "            if ((len(X_l) == 0) or (len(X_r) == 0)):\n",
    "                self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax(), np.bincount(y).astype(float) / len(y))\n",
    "            else:\n",
    "                self.tree[node_id] = (self.NON_LEAF_TYPE, feature_id, threshold)\n",
    "                self.__fit_node(X_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "                self.__fit_node(X_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "            if self.criterion == 'misclass':\n",
    "                uncert = (1 - np.max(np.sum(np.unique(y, return_counts=True)[1] / len(y))))\n",
    "                uncert_l = (1 - np.max(np.sum(np.unique(y_l, return_counts=True)[1] / len(y))))\n",
    "                uncert_r = (1 - np.max(np.sum(np.unique(y_r, return_counts=True)[1] / len(y))))\n",
    "                self.feature_importances_[feature_id] += (len(y) * uncert - len(y_l)\n",
    "                                                          * uncert_l - len(y_r) * uncert_r) / len(y)\n",
    "            elif self.criterion == 'gini':\n",
    "                uncert = (1 - np.sum(np.unique(y, return_counts=True)[1] ** 2 / len(y) ** 2))\n",
    "                uncert_l = (1 - np.sum(np.unique(y_l, return_counts=True)[1] ** 2 / len(y_l) ** 2))\n",
    "                uncert_r = (1 - np.sum(np.unique(y_r, return_counts=True)[1] ** 2 / len(y_r) ** 2))\n",
    "                self.feature_importances_[feature_id] += (len(y) * uncert - len(y_l)\n",
    "                                                          * uncert_l - len(y_r) * uncert_r) / len(y)\n",
    "            elif self.criterion == 'entropy':\n",
    "                uncert = - (np.sum((np.unique(y, return_counts=True)[1] / len(y)) \n",
    "                                   * np.log2(np.unique(y, return_counts=True)[1] / len(y))))\n",
    "                uncert_l = - (np.sum((np.unique(y_l, return_counts=True)[1] / len(y_l))\n",
    "                                     * np.log2(np.unique(y_l, return_counts=True)[1] / len(y_l))))\n",
    "                uncert_r = - (np.sum((np.unique(y_r, return_counts=True)[1] / len(y_r))\n",
    "                                     * np.log2(np.unique(y_r, return_counts=True)[1] / len(y_r))))\n",
    "                self.feature_importances_[feature_id] += (len(y) * uncert - len(y_l)\n",
    "                                                          * uncert_l - len(y_r) * uncert_r) / len(y)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Рекурсивно строим дерево решений\n",
    "        Начинаем с корня node_id 0\n",
    "        \"\"\"\n",
    "        self.feature_importances_ = np.zeros(x.shape[1], dtype='float')\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        \"\"\"\n",
    "        Рекурсивно обходим дерево по всем узлам,\n",
    "        пока не дойдем до терминального\n",
    "        \"\"\"\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Вызывает predict для всех объектов из матрицы X\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Возвращает важность признаков\n",
    "        \"\"\"\n",
    "        return self.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444444"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускоряем дерево решений (2 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine. \n",
    "Для этого используем numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 ms, sys: 718 µs, total: 2.38 ms\n",
      "Wall time: 1.43 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 ms, sys: 1.4 ms, total: 16.3 ms\n",
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Боевое применение (3 балла)\n",
    "\n",
    "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match). \n",
    "\n",
    "Пример работы с датасетом можете найти в практике пункт 2\n",
    "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
    "\n",
    "Данные и описания колонок лежат тут\n",
    "https://cloud.mail.ru/public/8nHV/p6J7wY1y1/speed-dating-experiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/Speed Dating Data.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 195)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удалим ненужные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, :97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id', 'idg', 'condtn', 'position', 'positin1', 'round', 'order',\n",
    "             'partner', 'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int',\n",
    "              'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'dec_o', 'attr_o', 'sinc_o', \n",
    "              'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o','met_o', 'field',\n",
    "              'undergra', 'from', 'zipcode','career', 'sports','tvsports','exercise',\n",
    "              'dining','museums','art','hiking','gaming','clubbing','reading','tv',\n",
    "              'theater','movies','concerts','music','shopping','yoga', 'expnum'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "5        1\n",
       "6        1\n",
       "7        1\n",
       "8        1\n",
       "9        1\n",
       "10       1\n",
       "11       1\n",
       "12       1\n",
       "13       1\n",
       "14       1\n",
       "15       1\n",
       "16       1\n",
       "17       1\n",
       "18       1\n",
       "19       1\n",
       "20       2\n",
       "21       2\n",
       "22       2\n",
       "23       2\n",
       "24       2\n",
       "25       2\n",
       "26       2\n",
       "27       2\n",
       "28       2\n",
       "29       2\n",
       "        ..\n",
       "8348     8\n",
       "8349     8\n",
       "8350     8\n",
       "8351     8\n",
       "8352     8\n",
       "8353     8\n",
       "8354     8\n",
       "8355     8\n",
       "8356    18\n",
       "8357    18\n",
       "8358    18\n",
       "8359    18\n",
       "8360    18\n",
       "8361    18\n",
       "8362    18\n",
       "8363    18\n",
       "8364    18\n",
       "8365    18\n",
       "8366    18\n",
       "8367    18\n",
       "8368    18\n",
       "8369    18\n",
       "8370    18\n",
       "8371    18\n",
       "8372    18\n",
       "8373    18\n",
       "8374    18\n",
       "8375    18\n",
       "8376    18\n",
       "8377    18\n",
       "Name: field_cd, Length: 8283, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['age'])\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(19)\n",
    "df.field_cd.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates('iid').mn_sat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nan решил заменить на минимальную оценку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float).fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1210c9898>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.drop_duplicates('iid').tuition.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates('iid').tuition.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство пропусков связано с тем, что университет находится не в штатах, но это тоже не точно как-то. Поэтому я в замешательстве. Возможно, если цена на обучение не указана, значит респондент учится на бюджетной основе, тогда можно заменить Nan на 0. Наверное, это самое логичное.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Положим Nan как other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4\n",
       "1       4\n",
       "2       4\n",
       "3       4\n",
       "4       4\n",
       "5       4\n",
       "6       4\n",
       "7       4\n",
       "8       4\n",
       "9       4\n",
       "10      2\n",
       "11      2\n",
       "12      2\n",
       "13      2\n",
       "14      2\n",
       "15      2\n",
       "16      2\n",
       "17      2\n",
       "18      2\n",
       "19      2\n",
       "20      2\n",
       "21      2\n",
       "22      2\n",
       "23      2\n",
       "24      2\n",
       "25      2\n",
       "26      2\n",
       "27      2\n",
       "28      2\n",
       "29      2\n",
       "       ..\n",
       "8348    1\n",
       "8349    1\n",
       "8350    1\n",
       "8351    1\n",
       "8352    1\n",
       "8353    1\n",
       "8354    1\n",
       "8355    1\n",
       "8356    2\n",
       "8357    2\n",
       "8358    2\n",
       "8359    2\n",
       "8360    2\n",
       "8361    2\n",
       "8362    2\n",
       "8363    2\n",
       "8364    2\n",
       "8365    2\n",
       "8366    2\n",
       "8367    2\n",
       "8368    2\n",
       "8369    2\n",
       "8370    2\n",
       "8371    2\n",
       "8372    2\n",
       "8373    2\n",
       "8374    2\n",
       "8375    2\n",
       "8376    2\n",
       "8377    2\n",
       "Name: race, Length: 8283, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.race.fillna(6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates('iid').imprace.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates('iid').imprelig.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пустых значений мало - просто удалим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['imprelig', 'imprace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       69487.0\n",
       "1       69487.0\n",
       "2       69487.0\n",
       "3       69487.0\n",
       "4       69487.0\n",
       "5       69487.0\n",
       "6       69487.0\n",
       "7       69487.0\n",
       "8       69487.0\n",
       "9       69487.0\n",
       "10      65929.0\n",
       "11      65929.0\n",
       "12      65929.0\n",
       "13      65929.0\n",
       "14      65929.0\n",
       "15      65929.0\n",
       "16      65929.0\n",
       "17      65929.0\n",
       "18      65929.0\n",
       "19      65929.0\n",
       "20          NaN\n",
       "21          NaN\n",
       "22          NaN\n",
       "23          NaN\n",
       "24          NaN\n",
       "25          NaN\n",
       "26          NaN\n",
       "27          NaN\n",
       "28          NaN\n",
       "29          NaN\n",
       "         ...   \n",
       "8348    55138.0\n",
       "8349    55138.0\n",
       "8350    55138.0\n",
       "8351    55138.0\n",
       "8352    55138.0\n",
       "8353    55138.0\n",
       "8354    55138.0\n",
       "8355    55138.0\n",
       "8356        NaN\n",
       "8357        NaN\n",
       "8358        NaN\n",
       "8359        NaN\n",
       "8360        NaN\n",
       "8361        NaN\n",
       "8362        NaN\n",
       "8363        NaN\n",
       "8364        NaN\n",
       "8365        NaN\n",
       "8366        NaN\n",
       "8367        NaN\n",
       "8368        NaN\n",
       "8369        NaN\n",
       "8370        NaN\n",
       "8371        NaN\n",
       "8372        NaN\n",
       "8373        NaN\n",
       "8374        NaN\n",
       "8375        NaN\n",
       "8376        NaN\n",
       "8377        NaN\n",
       "Name: income, Length: 8267, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "df.income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'income'] = df.loc[:, 'income'].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "5       1\n",
       "6       1\n",
       "7       1\n",
       "8       1\n",
       "9       1\n",
       "10      1\n",
       "11      1\n",
       "12      1\n",
       "13      1\n",
       "14      1\n",
       "15      1\n",
       "16      1\n",
       "17      1\n",
       "18      1\n",
       "19      1\n",
       "20      1\n",
       "21      1\n",
       "22      1\n",
       "23      1\n",
       "24      1\n",
       "25      1\n",
       "26      1\n",
       "27      1\n",
       "28      1\n",
       "29      1\n",
       "       ..\n",
       "8348    3\n",
       "8349    3\n",
       "8350    3\n",
       "8351    3\n",
       "8352    3\n",
       "8353    3\n",
       "8354    3\n",
       "8355    3\n",
       "8356    1\n",
       "8357    1\n",
       "8358    1\n",
       "8359    1\n",
       "8360    1\n",
       "8361    1\n",
       "8362    1\n",
       "8363    1\n",
       "8364    1\n",
       "8365    1\n",
       "8366    1\n",
       "8367    1\n",
       "8368    1\n",
       "8369    1\n",
       "8370    1\n",
       "8371    1\n",
       "8372    1\n",
       "8373    1\n",
       "8374    1\n",
       "8375    1\n",
       "8376    1\n",
       "8377    1\n",
       "Name: go_out, Length: 8249, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.goal.astype(int)\n",
    "df = df.dropna(subset=['date'])\n",
    "df.date.astype(int)\n",
    "df.go_out.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.career_c.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       18.0\n",
       "1       18.0\n",
       "2       18.0\n",
       "3       18.0\n",
       "4       18.0\n",
       "5       18.0\n",
       "6       18.0\n",
       "7       18.0\n",
       "8       18.0\n",
       "9       18.0\n",
       "10      18.0\n",
       "11      18.0\n",
       "12      18.0\n",
       "13      18.0\n",
       "14      18.0\n",
       "15      18.0\n",
       "16      18.0\n",
       "17      18.0\n",
       "18      18.0\n",
       "19      18.0\n",
       "20      18.0\n",
       "21      18.0\n",
       "22      18.0\n",
       "23      18.0\n",
       "24      18.0\n",
       "25      18.0\n",
       "26      18.0\n",
       "27      18.0\n",
       "28      18.0\n",
       "29      18.0\n",
       "        ... \n",
       "8348     7.0\n",
       "8349     7.0\n",
       "8350     7.0\n",
       "8351     7.0\n",
       "8352     7.0\n",
       "8353     7.0\n",
       "8354     7.0\n",
       "8355     7.0\n",
       "8356    15.0\n",
       "8357    15.0\n",
       "8358    15.0\n",
       "8359    15.0\n",
       "8360    15.0\n",
       "8361    15.0\n",
       "8362    15.0\n",
       "8363    15.0\n",
       "8364    15.0\n",
       "8365    15.0\n",
       "8366    15.0\n",
       "8367    15.0\n",
       "8368    15.0\n",
       "8369    15.0\n",
       "8370    15.0\n",
       "8371    15.0\n",
       "8372    15.0\n",
       "8373    15.0\n",
       "8374    15.0\n",
       "8375    15.0\n",
       "8376    15.0\n",
       "8377    15.0\n",
       "Name: career_c, Length: 8249, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.career_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = ['iid', 'wave', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "idx = ((temp.wave < 6) | (temp.wave > 9)) & (temp.totalsum < 99)\n",
    "idx = ((temp.wave >= 6) & (temp.wave <= 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']] = \\\n",
    "(df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = ['iid', 'wave', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']\n",
    "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "idx = ((temp.wave < 6) | (temp.wave > 9)) & (temp.totalsum < 90) & (temp.totalsum != 0)\n",
    "idx = ((temp.wave >= 6) & (temp.wave <= 9))\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "(df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['temp_totalsum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i), \n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i), \n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    \n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    \n",
    "    df = df.drop(feat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['wave'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis=1)\\\n",
    "                                 .dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1)\\\n",
    "                                   .dropna()\n",
    "        \n",
    "df_female.columns = df_female.columns + '_f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_female = df_female.drop(['pid_f'], axis=1)\n",
    "df_pair = df_male.join(df_female.set_index('iid_f'), on='pid', how='inner')\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "\n",
    "features = df_pair.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3999 entries, 100 to 8377\n",
      "Data columns (total 63 columns):\n",
      "match         3999 non-null int64\n",
      "int_corr      3999 non-null float64\n",
      "samerace      3999 non-null int64\n",
      "age           3999 non-null float64\n",
      "field_cd      3999 non-null float64\n",
      "mn_sat        3999 non-null float64\n",
      "tuition       3999 non-null float64\n",
      "race          3999 non-null float64\n",
      "imprace       3999 non-null float64\n",
      "imprelig      3999 non-null float64\n",
      "income        3999 non-null float64\n",
      "goal          3999 non-null float64\n",
      "date          3999 non-null float64\n",
      "go_out        3999 non-null float64\n",
      "career_c      3999 non-null float64\n",
      "exphappy      3999 non-null float64\n",
      "attr1_1       3999 non-null float64\n",
      "sinc1_1       3999 non-null float64\n",
      "intel1_1      3999 non-null float64\n",
      "fun1_1        3999 non-null float64\n",
      "amb1_1        3999 non-null float64\n",
      "shar1_1       3999 non-null float64\n",
      "attr2_1       3999 non-null float64\n",
      "sinc2_1       3999 non-null float64\n",
      "intel2_1      3999 non-null float64\n",
      "fun2_1        3999 non-null float64\n",
      "amb2_1        3999 non-null float64\n",
      "shar2_1       3999 non-null float64\n",
      "attr3_1       3999 non-null float64\n",
      "sinc3_1       3999 non-null float64\n",
      "fun3_1        3999 non-null float64\n",
      "intel3_1      3999 non-null float64\n",
      "amb3_1        3999 non-null float64\n",
      "age_f         3999 non-null float64\n",
      "field_cd_f    3999 non-null float64\n",
      "mn_sat_f      3999 non-null float64\n",
      "tuition_f     3999 non-null float64\n",
      "race_f        3999 non-null float64\n",
      "imprace_f     3999 non-null float64\n",
      "imprelig_f    3999 non-null float64\n",
      "income_f      3999 non-null float64\n",
      "goal_f        3999 non-null float64\n",
      "date_f        3999 non-null float64\n",
      "go_out_f      3999 non-null float64\n",
      "career_c_f    3999 non-null float64\n",
      "exphappy_f    3999 non-null float64\n",
      "attr1_1_f     3999 non-null float64\n",
      "sinc1_1_f     3999 non-null float64\n",
      "intel1_1_f    3999 non-null float64\n",
      "fun1_1_f      3999 non-null float64\n",
      "amb1_1_f      3999 non-null float64\n",
      "shar1_1_f     3999 non-null float64\n",
      "attr2_1_f     3999 non-null float64\n",
      "sinc2_1_f     3999 non-null float64\n",
      "intel2_1_f    3999 non-null float64\n",
      "fun2_1_f      3999 non-null float64\n",
      "amb2_1_f      3999 non-null float64\n",
      "shar2_1_f     3999 non-null float64\n",
      "attr3_1_f     3999 non-null float64\n",
      "sinc3_1_f     3999 non-null float64\n",
      "fun3_1_f      3999 non-null float64\n",
      "intel3_1_f    3999 non-null float64\n",
      "amb3_1_f      3999 non-null float64\n",
      "dtypes: float64(61), int64(2)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_pair.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pair.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_pair.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте датасет на трейн и валидацию. Подберите на валидации оптимальный критерий  информативности. \n",
    "Постройте графики зависимости точности на валидации от глубины дерева, от минимального числа объектов для сплита. \n",
    "Какой максимальной точности удалось достигнуть?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83375"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(my_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48278963051541174"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(my_clf.predict(X_test), y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5436885889861062"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(clf.predict(X_test), y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.735"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "crits = ('gini', 'entropy', 'misclass')\n",
    "scores = []\n",
    "for crit in crits:\n",
    "    model = MyDecisionTreeClassifier(criterion=crit)\n",
    "    scores.append(cross_val_score(model, X_train, y_train, cv=5, scoring='f1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.026894266022918435, 0.02445634475033005, 0.02169312169312169]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gini'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = crits[np.argmax(scores)]\n",
    "criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = np.arange(10, 20)\n",
    "scores = []\n",
    "for samples in min_samples_split:\n",
    "    model = MyDecisionTreeClassifier(criterion=criterion, min_samples_split=samples)\n",
    "    scores.append(cross_val_score(model, X_train, y_train, cv=5, scoring='f1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010346352247605013,\n",
       " 0.010346352247605013,\n",
       " 0.010346352247605013,\n",
       " 0.010346352247605013,\n",
       " 0.010346352247605013,\n",
       " 0.010346352247605013,\n",
       " 0.017302873986735447,\n",
       " 0.017302873986735447,\n",
       " 0.03130745064577435,\n",
       " 0.03130745064577435]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_samples_split = min_samples_split[np.argmax(scores)]\n",
    "min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "depthes = np.arange(2, 20)\n",
    "scores = []\n",
    "for depth in depthes:\n",
    "    model = MyDecisionTreeClassifier(criterion=criterion, min_samples_split=min_samples_split, max_depth=depth)\n",
    "    scores.append(cross_val_score(model, X_train, y_train, cv=5, scoring='f1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.010467980295566502,\n",
       " 0.010778635778635779,\n",
       " 0.03130745064577435,\n",
       " 0.04222738942379122,\n",
       " 0.05450565132490467,\n",
       " 0.060645021320362556,\n",
       " 0.06585177318601361,\n",
       " 0.07123695831252068,\n",
       " 0.07058881016437253,\n",
       " 0.06967285231430227,\n",
       " 0.06897268255862299,\n",
       " 0.06897268255862299,\n",
       " 0.06897268255862299,\n",
       " 0.06897268255862299,\n",
       " 0.06897268255862299,\n",
       " 0.06897268255862299,\n",
       " 0.06897268255862299]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = depthes[np.argmax(scores)]\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyDecisionTreeClassifier(criterion=criterion, min_samples_split=min_samples_split, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5131194454395953"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(model.predict(X_test), y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82375"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=model.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Находим самые важные признаки (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший. \n",
    "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
    "Выведите 10 главных фичей по важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyDecisionTreeClassifier(criterion=criterion, min_samples_split=min_samples_split, max_depth=max_depth)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shar1_1_f',\n",
       " 'intel1_1',\n",
       " 'field_cd_f',\n",
       " 'shar2_1_f',\n",
       " 'imprelig_f',\n",
       " 'fun3_1_f',\n",
       " 'field_cd',\n",
       " 'exphappy_f',\n",
       " 'income_f',\n",
       " 'int_corr']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features = model.get_feature_importance()\n",
    "list(features[np.argsort(important_features)[-10:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bit57b9abd1fbb540b9b129d58852a9e95f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
